# NLP Projects

This repository contains various Natural Language Processing (NLP) projects implemented in Jupyter Notebooks. Each project explores different techniques and models in NLP, leveraging popular datasets and libraries.

## Table of Contents
- [Bag-of-words](#bag-of-words)
- [IMDB_Analysis](#imdb_analysis)
- [Instruct](#instruct)
- [LSTM-Glove](#lstm-glove)
- [Seq2Seq-Autoatención](#seq2seq-autoatencion)
- [Transformer-Autoatención](#transformer-autoatencion)

## Bag-of-words
### Description
This project involves document similarity using the Bag-of-Words model and cosine similarity. The notebook covers data preprocessing, creation of the bag-of-words representation, and calculation of document similarity.

### Key Components
- **Data Preparation**: Preprocessing text by converting to lowercase, removing punctuation, and stopwords.
- **Bag-of-Words**: Creating a global vocabulary and representing each document as a vector in the vocabulary space.
- **Similarity Calculation**: Calculating cosine similarity between document vectors to determine document similarity.

### Usage
Execute the `Bag-of-words.ipynb` notebook to see the implementation and results.

### Files
- [Bag-of-words.ipynb](Bag-of-words/Bag-of-words.ipynb)

## IMDB_Analysis
### Description
Details not available for this project.

## Instruct
### Description
This project fine-tunes a language model using an "instruct" dataset to enhance its ability to respond to specific instructions or questions.

### Key Components
- **Instruction-based Training**: Training the model with pairs of instructions and expected responses.
- **Supervised Fine-Tuning**: Using supervised learning techniques to fine-tune the model with high-quality human-annotated data.

### Usage
Execute the `Instruct.ipynb` notebook to see the implementation and results.

### Files
- [Instruct.ipynb](Instruct/Instruct.ipynb)

## LSTM-Glove
### Description
This project applies a Long Short-Term Memory (LSTM) model to text classification tasks using the AG_NEWS dataset, and incorporates GloVe embeddings for word representation.

### Key Components
- **Dataset**: AG_NEWS dataset for text classification.
- **LSTM Model**: Implementing an LSTM model for text classification tasks.
- **GloVe Embeddings**: Using pre-trained GloVe embeddings to represent words.

### Usage
Execute the `LSTM-Glove.ipynb` notebook to see the implementation and results.

### Files
- [LSTM-Glove.ipynb](LSTM-Glove/LSTM-Glove.ipynb)

## Seq2Seq-Autoatención
### Description
Details not available for this project.

## Transformer-Autoatención
### Description
This project involves implementing the self-attention mechanism with masking in the Transformer model using PyTorch.

### Key Components
- **Self-Attention Mechanism**: Implementing self-attention with masking to prevent future information leakage.
- **Layer Normalization**: Applying layer normalization to stabilize training.
- **Matrix Operations**: Practicing matrix operations in PyTorch.

### Usage
Execute the `Transformer-Autoatención.ipynb` notebook to see the implementation and results.

### Files
- [Transformer-Autoatención.ipynb](Transformer-Autoatención/Transformer-Autoatención.ipynb)
