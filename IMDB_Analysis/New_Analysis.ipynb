{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<img src=\"../imgs/EII-ULPGC-logo.jpeg\" width=\"430px\" align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NOTEBOOK 9**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Estrategias de clasificaci√≥n**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Caso de uso: an√°lisis de sentimientos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El *sentiment analysis* o an√°lisis de sentimientos utiliza t√©cnicas de procesamiento de lenguaje natural para identificar y extraer informaci√≥n subjetiva de un texto, buscando determinar el estado de √°nimo o emoci√≥n expresada. Puede identificar polaridad (positivo, negativo, neutral), intensidad del sentimiento y sentimientos espec√≠ficos hacia aspectos concretos. Se emplea en monitoreo de redes sociales, an√°lisis de rese√±as de productos, servicio al cliente y an√°lisis de tendencias. A pesar de su utilidad, enfrenta desaf√≠os como iron√≠as, sarcasmos y contextos culturales que complican su precisi√≥n.\n",
    "\n",
    "\n",
    "El dataset de an√°lisis de sentimientos de **IMDB (Internet Movie Database)** creado por Stanford es uno de los datasets m√°s populares y ampliamente utilizados para la clasificaci√≥n de sentimientos en an√°lisis de texto. Fue creado por investigadores de la Universidad de Stanford y se utiliza principalmente para la tarea de clasificar las revisiones de pel√≠culas en \"positivas\" o \"negativas\".\n",
    "\n",
    "Caracter√≠sticas principales del dataset:\n",
    "\n",
    "1. **Tama√±o**: Contiene 50,000 rese√±as, de las cuales 25,000 son etiquetadas como positivas y 25,000 como negativas.\n",
    "2. **Balanceado**: Es un dataset equilibrado, lo que significa que hay un n√∫mero igual de rese√±as positivas y negativas.\n",
    "3. **Contenido**: Las rese√±as provienen de IMDB, y son rese√±as de pel√≠culas escritas por usuarios. \n",
    "4. **Etiquetado**: Las revisiones etiquetadas como positivas tienen una puntuaci√≥n ‚â• 7 sobre 10, mientras que las etiquetadas como negativas tienen una puntuaci√≥n ‚â§ 4 sobre 10. Las rese√±as con puntuaciones intermedias no est√°n incluidas en el conjunto de datos.\n",
    "\n",
    "Este dataset es especialmente √∫til para entrenar modelos de machine learning para an√°lisis de sentimiento y ha sido utilizado en varios trabajos de investigaci√≥n y proyectos. Adem√°s, dada su popularidad, muchos frameworks y bibliotecas, como TensorFlow y PyTorch, a menudo proporcionan utilidades para cargar f√°cilmente este conjunto de datos para experimentaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el fichero IMDB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('IMDB_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This a fantastic movie of three prisoners who ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment\n",
       "0   One of the other reviewers has mentioned that ...  positive\n",
       "1   A wonderful little production. <br /><br />The...  positive\n",
       "2   I thought this was a wonderful way to spend ti...  positive\n",
       "3   Basically there's a family where a little boy ...  negative\n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5   Probably my all-time favorite movie, a story o...  positive\n",
       "6   I sure would like to see a resurrection of a u...  positive\n",
       "7   This show was an amazing, fresh & innovative i...  negative\n",
       "8   Encouraged by the positive comments about this...  negative\n",
       "9   If you like original gut wrenching laughter yo...  positive\n",
       "10  Phil the Alien is one of those quirky films wh...  negative\n",
       "11  I saw this movie when I was about 12 when it c...  negative\n",
       "12  So im not a big fan of Boll's work but then ag...  negative\n",
       "13  The cast played Shakespeare.<br /><br />Shakes...  negative\n",
       "14  This a fantastic movie of three prisoners who ...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a desarrollar un pipeline usando `scikit-learn` para la clasificaci√≥n de sentimientos con el dataset de IMDB. El proceso general que vamos a seguir es:\n",
    "\n",
    "1. Cargar los datos.\n",
    "2. Preprocesar los datos.\n",
    "3. Dividir los datos en conjuntos de entrenamiento y prueba.\n",
    "4. Crear un clasificador Naive Bayes.\n",
    "5. Entrenar el clasificador y comprobar los resultados con los datos de prueba.\n",
    "\n",
    "Vamos a ello:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85      6157\n",
      "    positive       0.86      0.84      0.85      6343\n",
      "\n",
      "    accuracy                           0.85     12500\n",
      "   macro avg       0.85      0.85      0.85     12500\n",
      "weighted avg       0.85      0.85      0.85     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#quita los warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importando las bibliotecas necesarias\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Dividimos el DataFrame en datos y etiquetas\n",
    "X = df['review']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Creamos un vectorizador y un clasificador Naive Bayes\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=10000)\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Creamos un pipeline que incluya el vectorizador y el clasificador\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "# Entrenamos el modelo\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Comprobar los resultados con los datos de prueba\n",
    "predictions = pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Interpretaci√≥n de las medidas de desempe√±o de un modelo de clasificaci√≥n**\n",
    "\n",
    "Las medidas de desempe√±o son esenciales para evaluar la calidad y eficacia de un modelo de clasificaci√≥n. Vamos a explorar las medidas de desempe√±o m√°s comunes para modelos de clasificaci√≥n binaria. Supongamos que nuestro dataset de test est√° compuesto por 8 muestras positivas (azules) y 6 negativas (rojas). \n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"imgs/metrics1.svg\" width=\"27%\">\n",
    "</div>\n",
    "\n",
    "Una vez que hemos entrenado nuestro modelo, lo aplicamos sobre el conjunto de test y obtenemos las siguientes predicciones:\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"imgs/metrics2.svg\" width=\"27%\">\n",
    "</div>\n",
    "\n",
    "√âste determina que hay 7 muestras positivas y el resto negativas. Por tanto, el clasificador ha cometido errores. En realidad, tenemos 5 verdaderos positivos, 2 falsos positivos, 4 verdaderos negativos y 3 falsos negativos. Las medidas que tenemos para evaluar el desempe√±o del modelo son las siguientes:\n",
    "\n",
    "1. **Accuracy (Exactitud)**:\n",
    "Es la proporci√≥n de predicciones correctas entre el n√∫mero total de casos. Se calcula como el n√∫mero de verdaderos positivos m√°s el n√∫mero de verdaderos negativos dividido por el total de casos.\n",
    "    \n",
    "$$ \\text{Accuracy} = \\frac{\\text{Verdaderos Positivos + Verdaderos Negativos}}{\\text{Total de Casos}} $$\n",
    "\n",
    "2. **Precision (Precisi√≥n)**:\n",
    "Es la proporci√≥n de verdaderos positivos entre el n√∫mero total de positivos predichos por el modelo.\n",
    "    \n",
    "$$ \\text{Precision} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos + Falsos Positivos}} $$\n",
    "\n",
    "3. **Recall (Sensibilidad o Tasa de Verdaderos Positivos)**:\n",
    "Es la proporci√≥n de verdaderos positivos entre el n√∫mero total de casos reales positivos.\n",
    "\n",
    "$$ \\text{Recall} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos + Falsos Negativos}} $$\n",
    "\n",
    "4. **F1-Score (Puntuaci√≥n F1)**:\n",
    "Es una m√©trica que combina tanto la precisi√≥n como el recall en una sola cifra. Es especialmente √∫til si las clases est√°n desequilibradas. El valor de F1-Score var√≠a entre 0 y 1, donde 1 indica un rendimiento perfecto y 0 indica un rendimiento pobre.\n",
    "\n",
    "$$ \\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\n",
    "\n",
    "Observa que el F1-Score es la **media arm√≥nica** de la precisi√≥n y el recall. La media arm√≥nica es una media ponderada que da m√°s peso a los valores m√°s peque√±os. Por tanto, el F1-Score es m√°s sensible a los valores peque√±os de precisi√≥n y recall que la media aritm√©tica. \n",
    "\n",
    "5. **Support (Soporte)**:\n",
    "Refiere al n√∫mero de muestras reales que se encuentran en una determinada clase. Es esencialmente el n√∫mero de observaciones de la clase verdadera, sin tener en cuenta las predicciones del modelo.\n",
    "\n",
    "Cada una de estas m√©tricas ofrece una perspectiva diferente sobre la eficacia del modelo y, en conjunto, proporcionan una imagen completa del rendimiento del modelo en diversas situaciones. Por ejemplo, en casos donde el costo de un falso positivo es alto, se podr√≠a priorizar la precisi√≥n, mientras que en situaciones donde el costo de un falso negativo es alto, se podr√≠a priorizar el recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Medias aritm√©ticas vs. medias geom√©tricas vs. medias arm√≥nicas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media aritm√©tica: 0.5\n",
      "Media geom√©trica: 0.3556893304490063\n",
      "Media arm√≥nica: 0.2288135593220339\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   MEDIA ARITM√âTICA, GEOM√âTRICA Y ARM√ìNICA\n",
    "#\n",
    "\n",
    "a=0.1\n",
    "b=0.5\n",
    "c=0.9\n",
    "\n",
    "\n",
    "print(\"Media aritm√©tica: \" + str((a+b+c)/3))\n",
    "print(\"Media geom√©trica: \" + str((a*b*c)**(1/3)))\n",
    "print(\"Media arm√≥nica: \" + str(3/(1/a+1/b+1/c)))\n",
    "\n",
    "# Observa que, a menos que los tres n√∫meros sean iguales, la media geom√©trica es siempre menor que la media aritm√©tica, y la media arm√≥nica es siempre menor que la media geom√©trica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Ejercicio 1\n",
    "\n",
    "¬øC√≥mo se interpretan estas m√©tricas cuanto la classificaci√≥n es multiclase?\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Accuracy en multiclase:\n",
    "La accuracy en clasificaci√≥n multiclase se calcula de la misma manera que en la clasificaci√≥n binaria. Es la proporci√≥n de predicciones correctas (donde la clase predicha es igual a la clase real) entre el n√∫mero total de ejemplos. Se sigue usando la misma f√≥rmula:\n",
    "$$ \\text{Accuracy} = \\frac{\\text{Verdaderos Positivos + Verdaderos Negativos}}{\\text{Total de Casos}} $$\n",
    "\n",
    "### 2) Precision, Recall y F1-Score en multiclase:\n",
    "Estas m√©tricas son m√°s complicadas en el contexto multiclase porque ahora hay m√°s de dos clases. Para calcularlas, se suelen aplicar dos enfoques principales: macro y micro promediado, adem√°s del enfoque ponderado.\n",
    "\n",
    "##### a) Micro promedio:\n",
    "El enfoque micro considera cada predicci√≥n como una decisi√≥n individual sin importar la clase. Suma los verdaderos positivos, falsos positivos, y falsos negativos de todas las clases y luego calcula las m√©tricas:\n",
    "    \n",
    "-> Precision micro: Calcula la precisi√≥n global como si todas las clases fueran una sola clase.\n",
    "    $$ \\text{Precision micro} = \\frac{{‚àëVerdaderos¬†Positivos}}{{‚àë(Verdaderos¬†Positivos+Falsos¬†Positivos)}} $$\n",
    "-> Recall micro: Calcula la tasa de verdaderos positivos para todas las clases combinadas.\n",
    "    $$ \\text{Recall¬†Micro} = \\frac{{‚àëVerdaderos¬†Positivos}}{{‚àë(Verdaderos¬†Positivos+Falsos¬†Negativos)}} $$\n",
    "-> F1-Score micro: Usa la precisi√≥n y el recall calculados de manera micro para obtener el F1-Score.\n",
    "    $$ \\text{F1¬†Micro} = \\frac{{2 √ó PrecisionMicro √ó RecallMicro}}{{Precision Micro + Recall Micro}} $$\n",
    "\n",
    "#### b) Macro promedio:\n",
    "El enfoque macro calcula las m√©tricas para cada clase individualmente y luego promedia los resultados. Esto le da el mismo peso a cada clase, sin importar cu√°ntas observaciones tenga cada una.\n",
    "\n",
    "-> Precision macro: Se calcula la precisi√≥n para cada clase y luego se promedia.\n",
    "    $$ \\text{Precision Macro} = \\frac{{1}}{{n}}\\sum_{i=1}^{n} \\text{Precision}_i $$\n",
    "-> Recall macro: Se calcula el recall para cada clase y luego se promedia.\n",
    "    $$ \\text{Recall Macro} = \\frac{{1}}{{n}}\\sum_{i=1}^{n} \\text{Recall}_i $$\n",
    "-> F1-Score macro: Calcula el F1-Score para cada clase y luego se promedia.\n",
    "    $$ \\text{F1 Macro} = \\frac{{1}}{{n}}\\sum_{i=1}^{n} \\text{F1}_i $$\n",
    "\n",
    "#### c) Ponderado:\n",
    "El enfoque ponderado tiene en cuenta el n√∫mero de observaciones en cada clase. Calcula las m√©tricas por clase y luego las promedia ponderando por el tama√±o de cada clase.\n",
    "\n",
    "-> Precision ponderada:\n",
    "    $$ \\text{Precisi√≥n Ponderada} = \\frac{{1}}{{N}}\\sum_{i=1}^{n} \\text{Precisi√≥n}_i √ó \\text{Support}_i $$\n",
    "(Donde $\\text{Support}_i$ es el n√∫mero de muestras reales en la clase ùëñ y ùëÅ es el total de muestras.)\n",
    "-> Recall ponderado y F1 ponderado se calculan de manera similar.\n",
    "\n",
    "### 3) Support (Soporte):\n",
    "En el contexto multiclase, el soporte sigue siendo el n√∫mero de muestras reales en cada clase. Esto es √∫til para entender la distribuci√≥n de las clases y puede ayudar a interpretar si algunas clases est√°n poco representadas, lo que puede afectar las m√©tricas ponderadas.\n",
    "‚Äã\n",
    "\n",
    "‚Äã\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Ejercicio 2\n",
    "\n",
    "Realiza la clasificaci√≥n del dataset \"20 Newsgroups\". Para ello, usa el clasificador Naive Bayes y Regresi√≥n Log√≠stica. Compara los resultados obtenidos. Busca la configuraci√≥n √≥ptima de par√°metros para cada clasificador. Intenta mejorar los resultados obtenidos con otros clasificadores que puedas encontrar en la librer√≠a Scikit-Learn. Reporta la mejor soluci√≥n de todas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "newsgroups_data = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego dividimos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    newsgroups_data.data,\n",
    "    newsgroups_data.target,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=newsgroups_data.target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se un pipeline que incluya el vectorizador y el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english', max_features=10000)),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por √∫ltimo entrenamos el modelo y lo evaluamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8448275862068966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       160\n",
      "           1       0.67      0.82      0.73       195\n",
      "           2       0.86      0.03      0.06       197\n",
      "           3       0.58      0.82      0.68       196\n",
      "           4       0.77      0.91      0.83       193\n",
      "           5       0.78      0.88      0.83       198\n",
      "           6       0.82      0.84      0.83       195\n",
      "           7       0.85      0.90      0.88       198\n",
      "           8       0.86      0.94      0.90       199\n",
      "           9       0.94      0.94      0.94       199\n",
      "          10       0.98      0.94      0.96       200\n",
      "          11       0.95      0.94      0.95       198\n",
      "          12       0.82      0.86      0.84       197\n",
      "          13       0.95      0.88      0.91       198\n",
      "          14       0.95      0.90      0.93       197\n",
      "          15       0.94      0.94      0.94       199\n",
      "          16       0.84      0.92      0.88       182\n",
      "          17       0.98      0.92      0.95       188\n",
      "          18       0.87      0.85      0.86       155\n",
      "          19       0.86      0.69      0.77       126\n",
      "\n",
      "    accuracy                           0.84      3770\n",
      "   macro avg       0.86      0.84      0.83      3770\n",
      "weighted avg       0.86      0.84      0.83      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probaremos a utilizar diferentes clasificadores para probar que tan buenos son "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline_log = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english', max_features=10000)),\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8931034482758621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       160\n",
      "           1       0.78      0.84      0.81       195\n",
      "           2       0.84      0.82      0.83       197\n",
      "           3       0.77      0.79      0.78       196\n",
      "           4       0.88      0.84      0.86       193\n",
      "           5       0.85      0.90      0.88       198\n",
      "           6       0.83      0.86      0.84       195\n",
      "           7       0.92      0.90      0.91       198\n",
      "           8       0.95      0.91      0.93       199\n",
      "           9       0.96      0.96      0.96       199\n",
      "          10       0.97      0.97      0.97       200\n",
      "          11       0.96      0.95      0.96       198\n",
      "          12       0.82      0.83      0.83       197\n",
      "          13       0.89      0.94      0.92       198\n",
      "          14       0.98      0.94      0.96       197\n",
      "          15       0.91      0.94      0.93       199\n",
      "          16       0.91      0.91      0.91       182\n",
      "          17       0.97      0.94      0.95       188\n",
      "          18       0.89      0.88      0.89       155\n",
      "          19       0.91      0.76      0.83       126\n",
      "\n",
      "    accuracy                           0.89      3770\n",
      "   macro avg       0.89      0.89      0.89      3770\n",
      "weighted avg       0.89      0.89      0.89      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_log.fit(X_train, y_train)\n",
    "\n",
    "predictions_log = pipeline_log.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions_log))\n",
    "print(classification_report(y_test, predictions_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pipeline_SVC = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english', max_features=10000)),\n",
    "    ('clf', SVC(kernel='linear'))\n",
    "])\n",
    "\n",
    "pipeline_LinSVC = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english', max_features=10000)),\n",
    "    ('clf', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8591511936339522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       160\n",
      "           1       0.70      0.81      0.75       195\n",
      "           2       0.84      0.79      0.81       197\n",
      "           3       0.71      0.77      0.74       196\n",
      "           4       0.84      0.76      0.80       193\n",
      "           5       0.86      0.86      0.86       198\n",
      "           6       0.81      0.83      0.82       195\n",
      "           7       0.88      0.90      0.89       198\n",
      "           8       0.93      0.90      0.91       199\n",
      "           9       0.91      0.90      0.91       199\n",
      "          10       0.92      0.94      0.93       200\n",
      "          11       0.94      0.93      0.94       198\n",
      "          12       0.77      0.79      0.78       197\n",
      "          13       0.84      0.85      0.84       198\n",
      "          14       0.99      0.91      0.95       197\n",
      "          15       0.88      0.91      0.89       199\n",
      "          16       0.89      0.87      0.88       182\n",
      "          17       0.96      0.90      0.93       188\n",
      "          18       0.85      0.88      0.86       155\n",
      "          19       0.84      0.73      0.78       126\n",
      "\n",
      "    accuracy                           0.86      3770\n",
      "   macro avg       0.86      0.86      0.86      3770\n",
      "weighted avg       0.86      0.86      0.86      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_SVC.fit(X_train, y_train)\n",
    "\n",
    "predictions_SVC = pipeline_SVC.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions_SVC))\n",
    "print(classification_report(y_test, predictions_SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8824933687002653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       160\n",
      "           1       0.77      0.84      0.80       195\n",
      "           2       0.81      0.84      0.82       197\n",
      "           3       0.74      0.75      0.74       196\n",
      "           4       0.84      0.83      0.83       193\n",
      "           5       0.88      0.87      0.88       198\n",
      "           6       0.80      0.82      0.81       195\n",
      "           7       0.91      0.90      0.91       198\n",
      "           8       0.96      0.91      0.94       199\n",
      "           9       0.95      0.93      0.94       199\n",
      "          10       0.97      0.98      0.98       200\n",
      "          11       0.95      0.96      0.95       198\n",
      "          12       0.82      0.81      0.81       197\n",
      "          13       0.86      0.92      0.89       198\n",
      "          14       0.98      0.93      0.96       197\n",
      "          15       0.91      0.93      0.92       199\n",
      "          16       0.90      0.90      0.90       182\n",
      "          17       0.97      0.93      0.95       188\n",
      "          18       0.90      0.88      0.89       155\n",
      "          19       0.86      0.75      0.80       126\n",
      "\n",
      "    accuracy                           0.88      3770\n",
      "   macro avg       0.88      0.88      0.88      3770\n",
      "weighted avg       0.88      0.88      0.88      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_LinSVC.fit(X_train, y_train)\n",
    "\n",
    "predictions_LinSVC = pipeline_LinSVC.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions_LinSVC))\n",
    "print(classification_report(y_test, predictions_LinSVC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PLN2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
